# GPT-From-Scratch
GPT from scratch involves building a generative model using transformers, including components like tokenization, embedding layers, multi-head attention, and decoders. The model is trained on raw data for text generation.
